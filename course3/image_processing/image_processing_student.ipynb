{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9TwZyP598rJ"
      },
      "source": [
        "## Image processing\n",
        "\n",
        "In this practical session, we'll dive into the essentials of image processing, exploring how digital images are represented and manipulated. Our focus will span three key areas:\n",
        "\n",
        "- Basics About Images: Learn to display images and understand their structure, laying the foundation for all image processing tasks.\n",
        "\n",
        "- Mathematical Morphology: Delve into operations that manipulate the shape of objects in images, crucial for preprocessing and feature extraction.\n",
        "\n",
        "- Harris Corner Detector: Explore this algorithm for detecting corners, a critical feature in tasks like image matching and object recognition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GSlROOMAEzA"
      },
      "source": [
        "Let's load some image samples using the library `skimage`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uXrpnGn86iZz"
      },
      "outputs": [],
      "source": [
        "# Write you imports here\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB1F-d0VArQA"
      },
      "source": [
        "Load the colorwheel image from skimage (ski.data.colorwheel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "ksRQceqoAgrE"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sws8LAGA1g6"
      },
      "source": [
        "Display the shape of the image (it should be: (370, 371, 3))\n",
        "\n",
        "The first 2 dimensions of the dimensions are for the size of the image (number of pixels)\n",
        "\n",
        "The last dimension is the number of channels. Here its for red, green, blue (rgb image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbBEHHeOBrNj"
      },
      "source": [
        "Display the image, you can use plotly or matplotlib, as you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en8AcNibCsHp"
      },
      "source": [
        "Convert the image to grayscale\n",
        "\n",
        "The Formula for Grayscale Conversion:\n",
        "The most common method to convert an image to grayscale is to use a weighted sum of the RGB (Red, Green, Blue) values of each pixel. The formula reflects the human eye's sensitivity to different colors and is given by:\n",
        "\n",
        "$$\n",
        "Gray=0.2989×Red+0.5870×Green+0.1140×Blue\n",
        "$$\n",
        "\n",
        "This formula assigns higher weights to the green channel, acknowledging our eyes' greater sensitivity to green, followed by red and blue. By applying this formula, we convert each pixel's color value to a single intensity value, resulting in a grayscale image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnaNjA1dDZ8b"
      },
      "source": [
        "Then convert the image to grayscale but using the following formula\n",
        "\n",
        "$$\n",
        "Gray=0.2989×Red+0.5870×Green+0.1140×Blue\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ciucEmfaFF"
      },
      "source": [
        "#### Exploring Gaussian Blur and Contrast Adjustment\n",
        "\n",
        "\n",
        "In this section of the practical exercise, you will delve into two fundamental image processing techniques: Gaussian blur and contrast adjustment. These techniques are instrumental in enhancing image quality and feature visibility, making them crucial for tasks such as image segmentation and object recognition. You will use `skimage.filters.gaussian` for applying Gaussian blur and `skimage.exposure.equalize_adapthist` for adjusting the image contrast. By manipulating the hyperparameters of these functions, you will observe how each technique affects the image's appearance and quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHZopYDaeHaX"
      },
      "source": [
        "**Gaussian filter**\n",
        "\n",
        "Gaussian blur is a smoothing technique commonly used in image processing to reduce noise and detail. It works by convolving the image with a Gaussian function, effectively averaging the pixels in the vicinity of each point with weights decreasing with distance from the central pixel. This process results in a blur that preserves edges better than uniform averaging.\n",
        "\n",
        "Use the function `gaussian`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j5FoK2zegN0"
      },
      "source": [
        "**Contrast adjustment**\n",
        "\n",
        "Contrast in an image refers to the difference in luminance or color that makes an object distinguishable. In images with poor contrast, distinguishing features or details can be difficult. Adjusting the contrast can make these features more pronounced. Adaptive histogram equalization, and specifically its variant called Contrast Limited Adaptive Histogram Equalization (CLAHE), is a method for contrast adjustment that improves local contrast in images, particularly useful in areas that are darker or lighter than most of the image.\n",
        "\n",
        "\n",
        "Use the function `equalize_adapthist` from skimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfH-RwPAL7Mn"
      },
      "source": [
        "### Mathematical morphology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtN2vwYAM_WC"
      },
      "source": [
        "Mathematical morphology is a powerful set of image processing operations that focus on the shape or structure of features in an image. Originating from set theory, it provides tools for extracting image components useful for the representation and description of region shape, such as boundaries, skeletons, and the convex hull. In the context of biological imaging, such as segmenting cells from microscopy images, mathematical morphology can be instrumental. It helps in enhancing image structures relevant for segmentation, thereby facilitating the extraction of meaningful biological information. Operations like erosion, dilation, opening, and closing can remove noise, separate touching objects, and highlight regions of interest, making them essential for preprocessing before applying segmentation algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-1q-EiPNYXA"
      },
      "source": [
        "We are going to work on a cell image from skimage library.\n",
        "\n",
        "Please load the image, `skimage.data.cell()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUvuXGzNjx_"
      },
      "source": [
        "Now plot the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0f1X_XrN8I4"
      },
      "source": [
        "**Otsu thresholding method**\n",
        "\n",
        "We are going to convert our image, from grayscale to binary image representation. In order to achieve this goal, we will use the otsu thresholding method.\n",
        "\n",
        "In the context of segmenting cells from microscopy images or similar tasks, the purpose of using threshold_otsu is multifold:\n",
        "\n",
        "Automatic Thresholding: Otsu's method automatically calculates the threshold value based on the image's histogram, making it suitable for applications where the intensity distribution of the image is not known in advance or varies between images. This automation is particularly beneficial in batch processing of images where manual threshold selection would be impractical.\n",
        "\n",
        "Contrast Enhancement: By separating the foreground from the background, Otsu's thresholding can enhance the contrast between objects of interest (e.g., cells) and the surrounding medium, making subsequent morphological operations more effective in isolating and segmenting the desired features.\n",
        "\n",
        "Preprocessing Step: It serves as an essential preprocessing step that simplifies the image, reducing it to a form that is easier to analyze and process with morphological operations. This simplification can significantly improve the performance and accuracy of the segmentation process.\n",
        "\n",
        "Versatility: Although simple, Otsu's method is remarkably versatile and effective across a wide range of applications, particularly in biomedical image analysis where the contrast between objects and background can vary significantly.\n",
        "\n",
        "Actually, this algorithm will be enough to segment our cell image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrqfJpitOO9D"
      },
      "source": [
        "Use the `threshold_otsu` from skimage.filters\n",
        "\n",
        "to find the optimal threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLx-oXj0OvqO"
      },
      "source": [
        "Once you have the optimal Otsu threshold to binarize the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UQ4-P92PsLj"
      },
      "source": [
        "Now let's load another images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g4ie3uUBP8h7"
      },
      "outputs": [],
      "source": [
        "from skimage import io\n",
        "data = io.imread(\"https://github.com/scikit-image/skimage-tutorials/raw/main/images/cells.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxcu_YNiQCxm"
      },
      "source": [
        "Display the shape of `data`, you should have (60, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DhfGYGGQI-g"
      },
      "source": [
        "it means we have 60 images of shape (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aYAEHbBRT8W"
      },
      "source": [
        "The data we have comes in the form of a three-dimensional (3D) array with the shape of (60, 256, 256). This means we have 60 slices or layers, and each slice is an image that is 256 pixels wide and 256 pixels tall. Think of this as a stack of 60 photos, each showing a slightly different section of the same object or body part. These images are often obtained from advanced medical imaging techniques like MRI or CT scans, which let us see inside the human body without surgery.\n",
        "\n",
        "**MRI (Magnetic Resonance Imaging)** is a technique that uses a strong magnetic field and radio waves to create detailed images of the organs and tissues within the body. It's particularly useful for imaging the brain, muscles, and heart, as it can capture the details of soft tissues very well.\n",
        "\n",
        "**CT (Computed Tomography)** scans, on the other hand, use X-rays to create comprehensive images. Unlike a regular X-ray that shows only a flat image, a CT scan provides a 3D image by taking multiple X-ray measurements from different angles. This makes it extremely useful for examining structures like bones, blood vessels, and tumors.\n",
        "\n",
        "When we analyze such data, especially from MRI or CT scans, we're essentially looking through these \"slices\" to understand the structure and condition of the body part in question. Each slice gives us a view of a thin section of the body, and by examining these slices in sequence, we can get a complete picture of the internal anatomy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udxNb1SLQN8Q"
      },
      "source": [
        "Now plot the first images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI_I96CSS7J6"
      },
      "source": [
        "Plot the first 20 images\n",
        "\n",
        "With plotly you can directly plot multiple images.\n",
        "\n",
        "Investigate: `imshow` `facet_col` `binary_string` `facet_col_wrap`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2__-7JmCTPhV"
      },
      "source": [
        "Now plot the following 20 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaP1lmfvTzJp"
      },
      "source": [
        "Now select the 30th image, and plot the image, or any other image, as you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R1dEQPJhtmF"
      },
      "source": [
        "We are going to segment and extract the cells from the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kTjUFdUl0t"
      },
      "source": [
        "Apply the Otsu thresholding method, to convert the image from grayscale to binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_ZXSPZNVib8"
      },
      "source": [
        "Plot the binary image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyZJgu7nVk0N"
      },
      "source": [
        "Try to apply morphology operators, like:\n",
        "- binary opening\n",
        "- binary closing\n",
        "- remove small holes\n",
        "- area opening\n",
        "- area closing\n",
        "- ...\n",
        "\n",
        "from skimage morphology library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAjy3zEWazqx"
      },
      "source": [
        "`skimage.morphology.remove_small_holes`\n",
        "\n",
        "remove_small_holes is a function designed to fill small holes in binary images. A \"hole\" in this context refers to a set of background pixels (typically valued 0) that are completely enclosed by foreground pixels (typically valued 1). The function's purpose is to enhance image segmentation quality by ensuring that objects of interest are solid without internal gaps that might interfere with analysis.\n",
        "\n",
        "How it works:\n",
        "\n",
        "- Identification of Holes: The algorithm first identifies all background regions that are not connected to the image border. Any such region is considered a hole because it is surrounded by the foreground.\n",
        "\n",
        "- Size Filtering: Each identified hole is then compared against a specified size threshold. If the hole's area (the number of pixels it contains) is smaller than this threshold, it is filled; otherwise, it is left unchanged.\n",
        "\n",
        "- Filling Holes: Filling is achieved by changing the value of all pixels in the hole from the background value (0) to the foreground value (1).\n",
        "This operation is particularly useful for post-processing binary segmentation results where small gaps within objects can adversely affect morphological analyses or object counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE-YYMnabtPY"
      },
      "source": [
        "`skimage.morphology.area_closing`\n",
        "\n",
        "area_closing is related to the concept of morphological closing but operates based on the area of dark regions instead of structuring element shape and size. This operation is applied to grayscale (or binary) images and is intended to remove small dark spots and small black holes on the foreground objects.\n",
        "\n",
        "How it works:\n",
        "\n",
        "- Dark Spot Identification: It identifies all dark regions (sets of connected dark pixels) in the image.\n",
        "\n",
        "- Size Thresholding: Each dark region's area is compared against a specified threshold. Dark regions smaller than this threshold are considered noise or small holes and are filled in to match the surrounding brighter area.\n",
        "\n",
        "- Application: The operation smooths the contour of bright regions and fills in dark spots and holes within those bright regions, without significantly altering the overall shapes.\n",
        "\n",
        "Area closing is particularly effective for smoothing the contours of bright structures and closing small dark gaps within them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxg5Deeob0L4"
      },
      "source": [
        "`skimage.morphology.area_opening`\n",
        "\n",
        "Conversely, area_opening targets the removal of small bright structures from a dark background. It is the counterpart to area_closing and is useful for cleaning up noise in dark regions without affecting the larger, more significant bright structures.\n",
        "\n",
        "How it works:\n",
        "\n",
        "- Bright Spot Identification: Identifies all bright regions in the image.\n",
        "\n",
        "- Size Thresholding: Compares the area of these bright regions against a specified threshold. Bright regions that are smaller than this threshold are considered to be noise or insignificant objects and are removed (their pixels are made darker to match the surrounding area).\n",
        "\n",
        "- Application: This operation smooths the contours of dark regions by removing small bright spots and artifacts within them, enhancing the clarity and focus on significant objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "192AbFY0GNAm"
      },
      "source": [
        "### Let's detect corners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esavYtVVGxWG"
      },
      "source": [
        "Here we will leverage OpenCV's Harris Corner Detector to identify and analyze key feature points within images, enabling us to explore the intricacies of feature detection in digital image processing.\n",
        "\n",
        "A corner in an image represents a point of interest where the direction of edges changes significantly, which typically corresponds to a variation in intensity that indicates a notable feature within the image. Corners are considered crucial in many computer vision tasks because they are easily detectable and are invariant to rotation, translation, and, to some extent, scale changes. These properties make corners suitable for tasks like image matching, object recognition, and scene reconstruction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xC7a7ruG19a"
      },
      "source": [
        "Now same as before, load the checkerboard from skimage.data\n",
        "\n",
        "display the shape and plot the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIU9A3nzJQl0"
      },
      "source": [
        "Now it's time to compute the Harris Corner Detector using OpenCV in Python\n",
        "\n",
        "Use the `cornerHarris` function from opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuK0IwJ9LlnI"
      },
      "source": [
        "it returns an output array (dst in the provided code) where each pixel value corresponds to the Harris Corner response. Higher values in this array indicate a higher likelihood of a corner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dv0j40ui7HS"
      },
      "source": [
        "Now plot the image, with red points on all the corners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rppkFsZiG5b4"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
