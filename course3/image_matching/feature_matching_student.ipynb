{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWJnpPetu9P8"
      },
      "source": [
        "## Introduction to ORB and Keypoint Detection\n",
        "\n",
        "Objective: Familiarize yourself with ORB (Oriented FAST and Rotated BRIEF), a feature detector and descriptor. You'll load images, detect keypoints, and extract ORB descriptors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nunDmTcTwYwY"
      },
      "source": [
        "### ORB (Oriented FAST and Rotated BRIEF)\n",
        "\n",
        "ORB is a fast robust local feature detector, first introduced by Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary R. Bradski in their 2011 paper. ORB is essentially a fusion of FAST keypoint detector and BRIEF descriptor with some modifications to enhance performance. It is designed to be faster and more efficient than its predecessors like SIFT and SURF while providing good resistance to noise and being able to handle rotation changes efficiently. Here's a detailed explanation of how ORB works:\n",
        "\n",
        "1. FAST Keypoint Detection\n",
        "ORB starts with a FAST (Features from Accelerated Segment Test) detector to find keypoints. The FAST detector identifies corners in an image by considering a circle of sixteen pixels around the candidate pixel. It classifies a pixel as a corner if there are n contiguous pixels in the circle which are all brighter than the candidate pixel plus a threshold or all darker than the candidate pixel minus a threshold. The original FAST does not compute the orientation of keypoints, which is necessary for achieving rotation invariance.\n",
        "\n",
        "2. Orientation Computation\n",
        "To add orientation to the keypoints, ORB computes the intensity weighted centroid of a patch around the keypoint. The vector from the center of the patch to this centroid gives the orientation. This method ensures that the orientation is invariant to scale and rotation.\n",
        "\n",
        "3. Harris Corner Measure\n",
        "Although FAST is good at detecting keypoints, it selects too many. To reduce the number and only keep the most prominent ones, ORB uses the Harris corner measure to rank the keypoints. It then selects the top N keypoints based on the Harris score (or FAST score if Harris is not preferred due to performance reasons).\n",
        "\n",
        "4. BRIEF Descriptor\n",
        "After detecting and orienting the keypoints, ORB uses a modified version of the BRIEF (Binary Robust Independent Elementary Features) descriptor to generate a feature descriptor for each keypoint. BRIEF creates a binary string description of an image patch by comparing the intensity of pairs of pixels in a small region around the keypoint.\n",
        "\n",
        "5. Rotation Awareness and Steering\n",
        "The original BRIEF descriptor is not rotation invariant, which is a problem for matching keypoints between images that have been rotated relative to each other. To solve this, ORB steers the BRIEF according to the orientation of keypoints. This means rotating the BRIEF's pattern to match the keypoint's orientation, ensuring that the descriptor is rotation invariant.\n",
        "\n",
        "6. Scale Invariance\n",
        "ORB achieves scale invariance by constructing a pyramid of down-scaled images. Keypoints are detected at each level of the pyramid, which allows ORB to detect and match features across images with different scales.\n",
        "\n",
        "7. Fast Binary Descriptor Matching\n",
        "The binary nature of the ORB descriptor allows for using the Hamming distance to compare descriptors, which can be done very efficiently with modern CPUs, especially using popcount (counting the number of set bits in a binary word) instructions. This efficiency makes ORB particularly well-suited for real-time applications.\n",
        "\n",
        "Summary\n",
        "ORB is a powerful feature detector and descriptor that offers a good balance between speed, efficiency, and performance. It does so by cleverly integrating and modifying existing algorithms (FAST and BRIEF) and adding mechanisms to ensure rotation and scale invariance, making it suitable for a wide range of computer vision applications, especially those requiring real-time performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myy84mMgvyIe"
      },
      "source": [
        "**Create ORB descriptor**\n",
        "\n",
        "Load two images: 'box.png' as the query image and 'box_in_scene.png' as the train image.\n",
        "\n",
        "Use cv.imread with cv.IMREAD_GRAYSCALE to load images in grayscale.\n",
        "\n",
        "Initialize the ORB detector using `ORB_create`.\n",
        "\n",
        "Detect keypoints and compute descriptors for both images using orb.\n",
        "\n",
        "`detectAndCompute`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LHZuu5lO1EU7"
      },
      "outputs": [],
      "source": [
        "# Task 1: Load images in grayscale\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LLm9m692FNu",
        "outputId": "27e17632-0a02-499d-d46d-0df46945df5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((223, 324), (384, 512))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the shape\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFjObQKz19mS"
      },
      "source": [
        "Display both images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s_vNAuem1GYt"
      },
      "outputs": [],
      "source": [
        "# Task 2: Initiate ORB detector (use ORB_create() function)\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xTcVmOPB1Icg"
      },
      "outputs": [],
      "source": [
        "# Task 3: Detect keypoints and compute descriptors (use detectAndCompute(img_name, None))\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WJbvczwwi9-"
      },
      "source": [
        "**Implementing Brute-Force Matching with ORB Descriptors**\n",
        "\n",
        "Objective: Learn how to use the Brute-Force matcher to find matches between descriptors of two images.\n",
        "\n",
        "Brute-Force matcher:\n",
        "\n",
        "- The BFMatcher takes each descriptor from the first set and compares it against all descriptors in the second set using a distance metric.\n",
        "\n",
        "- The match between two descriptors is determined based on the distance metric. The lower the distance, the better the match. For binary descriptors, the Hamming distance is often preferred as it is faster to compute, especially with hardware support for popcount operations.\n",
        "\n",
        "BFMatcher provides two primary methods for retrieving matches:\n",
        "\n",
        "match(): This method finds the best match for each descriptor in the first set. It returns a list of the best matches, each of which corresponds to a single descriptor comparison. This is useful when you only need the best match for each feature.\n",
        "\n",
        "knnMatch(): This method finds the top k matches for each descriptor in the first set, where k is specified by the user. This is particularly useful for applying filters on the matches, such as the Lowe's ratio test, which compares the distance of the best match to the distance of the second-best match to discard poor matches.\n",
        "\n",
        "\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Create a BFMatcher object with cv.NORM_HAMMING and crossCheck=True.\n",
        "Match descriptors using the match() method of BFMatcher. Have a look at the documentation of OpenCV.\n",
        "\n",
        "Sort the matches based on their distance.\n",
        "\n",
        "Draw the top 10 matches using cv.drawMatches and display the result with plt.imshow().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fJ5AhlE508YG"
      },
      "outputs": [],
      "source": [
        "# Task 1: Create BFMatcher object\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z9kP-ULH0-L-"
      },
      "outputs": [],
      "source": [
        "# Task 2: Match descriptors\n",
        "# once you have created your BFMatcher\n",
        "# then you can call bf.match(...)\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3wzciwFc0_05"
      },
      "outputs": [],
      "source": [
        "# Task 3: Sort matches\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 4: Draw and display matches (drawMatches function from openCV)\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ocJ1qPvw-bN"
      },
      "source": [
        "**Applying Lowe's Ratio Test for Reliable Matching**\n",
        "\n",
        "Objective: Apply Lowe's ratio test to filter out unreliable matches. This method helps in reducing false positives.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Use knnMatch() of BFMatcher to find the 2 best matches for each descriptor.\n",
        "Apply Lowe's ratio test (e.g., if the distance of the best match is less than 75% of the second-best match, keep this match).\n",
        "\n",
        "Draw and display the good matches that pass the ratio test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xWMEbf-I1O96"
      },
      "outputs": [],
      "source": [
        "# Task 1: Find 2 best matches for each descriptor\n",
        "# Create the BFMatcher\n",
        "# Call the knnMatch function from your BFMatcher object\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a1enYN_l1QsT"
      },
      "outputs": [],
      "source": [
        "# Task 2: Apply Lowe's ratio test\n",
        "# https://stackoverflow.com/questions/51197091/how-does-the-lowes-ratio-test-work\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 3: Draw and display good matches\n",
        "# Call the function drawMatchesKnn\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f9Xp7F3xJDt"
      },
      "source": [
        "**Exploring FLANN Based Matcher**\n",
        "\n",
        "Objective: Experiment with the FLANN based matcher, which is more suitable for large datasets or high-dimensional features.\n",
        "\n",
        "The FLANN based matcher (Fast Library for Approximate Nearest Neighbors) is an algorithm used for efficiently finding approximate nearest neighbors in large datasets or high-dimensional spaces. In the context of computer vision, FLANN is used to match feature descriptors between images more quickly than a brute-force approach, especially when dealing with a large number of features. It is particularly useful in applications requiring fast performance, such as real-time image matching, object recognition, and 3D reconstruction.\n",
        "\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Define FLANN matcher parameters and initialize the FLANN matcher.\n",
        "Use knnMatch() to find matches and apply Lowe's ratio test.\n",
        "Draw the good matches and display the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "COTPBkt51bPT"
      },
      "outputs": [],
      "source": [
        "# Task 1: Define FLANN matcher parameters and initialize\n",
        "# Create the FlannBasedMatcher(...) object\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "heuV2zw61cUU"
      },
      "outputs": [],
      "source": [
        "# Task 2: Find matches and apply Lowe's ratio test\n",
        "# Call the knnMatch function and then filter the matches\n",
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "VN9ssUbhxLst",
        "outputId": "afed6cd8-529e-48e7-b5bc-2ae42172a97c"
      },
      "outputs": [],
      "source": [
        "# Task 3: Draw and display good matches\n",
        "# call drawMatchesKnn\n",
        "# FIXME\n",
        "\n",
        "# Display the result\n",
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
